---
layout: post
title: Automatic Speech Recognition - Speech Signal Analysis
date: 2018-1-18
categories: blog
tags: [ASR,NLP]
description: Speech Signal Analysis for ASR。
---  

## Speech production model  
![loading](https://raw.githubusercontent.com/zhiyou720/zhiyou720.github.io/master/img/ASR/ASR-02-01.png)

## A/D conversion — Sampling  
Convert analogue signals(模拟信号) in digital form  
![loading](https://raw.githubusercontent.com/zhiyou720/zhiyou720.github.io/master/img/ASR/ASR-02-02.png)
Things to know:  
- Sampling Frequency ($$F_s = 1/T_s$$)
![loading](https://raw.githubusercontent.com/zhiyou720/zhiyou720.github.io/master/img/ASR/ASR-02-03.png)  
- Analogue low-pass filtering to avoid ’aliasing’(混淆)  
NB: the cut-off frequency should be less than the *Nyquist frequency* ($$= F_s/2$$)  

## Acoustic Features for ASR
![loading](https://raw.githubusercontent.com/zhiyou720/zhiyou720.github.io/master/img/ASR/ASR-02-04.png)  
Speech signal analysis to produce a sequence of acoustic feature vectors.  

### Desirable characteristics of acoustic features used for ASR:  
- Features should contain sufficient information to distinguish between phones.  
  - good time resolution (10ms)  
  - good frequency resolution (20 ∼ 40 channels)  
- Be separated from $$F_0$$ and its harmonics(谐波)  
- Be robust against speaker variation(变异)
- Be robust against noise or channel distortions(扭曲)
- Have good “pattern recognition characteristics”
  - low feature dimension
  - features are independent of each other (NB: this applies to GMMs, but not required for NN-based systems)  
  
## MFCC-based front end for ASR
![loading](https://raw.githubusercontent.com/zhiyou720/zhiyou720.github.io/master/img/ASR/ASR-02-05.png)  

## Pre-emphasis and spectral tilt(频谱倾斜)
- Pre-emphasis increases the magnitude(量级) of higher frequencies in the speech signal compared with lower frequencies.
- *Spectral Tilt* 
  - The speech signal has more energy at low frequencies (for voiced speech).
  - This is due to the glottal(声门发声的) source (see the figure)
- Pre-emphasis (first-order) filter boosts higher frequencies:
  - $$x'[t_d]=x[t_d]-\alpha x [t_d-1] \quad \quad 0.95<\alpha<0.99$$  
  
### Examlpe
![loading](https://raw.githubusercontent.com/zhiyou720/zhiyou720.github.io/master/img/ASR/ASR-02-06.png)  

## Windowing  
- The speech signal is constantly changing (non-stationary(静止)).  
- Signal processing algorithms usually assume that the signal is stationary  
- Piecewise(分段) stationarity: model speech signal as a sequence of frames (each assumed to be stationary)
- *Windowing*: multiply the full waveform $$s[n]$$ by a window $$w[n]$$ (in time domain):    
<center>$$x[n] = w[n]s[n] \quad\quad (x_t[n] = w[n]x'[t_d+n])$$</center>  
- Simply cutting out a short segment(分段) (frame) from $$s[n]$$ is a rectangular(矩形) window — causes discontinuities at the edges of the segment.  
- Instead, a tapered(锥形的) window is usually used.  
  - e.g. *Hamming* ($$\alpha$$ = 0.46164) or *Hanning* ($$\alpha$$ = 0.5) window
<center>$$w[n] = (1−\alpha) − \alpha cos(\frac{2\pi n}{L-1}) \quad\quad L : window\quad width$$</center>

### Windowing and spectral analysis(频谱分析)
- Window the signal $$x‘[t_d]$$ into frames $$x_t[n]$$ and apply Fourier Transform(傅立叶变换) to each segment.   
  - Short frame width: wide-band, high time resolution(分辨率), low frequency resolution
  - Long frame width: narrow-band, low time resolution, high frequency resolution
- For ASR:
  - frame width ∼ 25ms
  - frame shift ∼ 10ms
![loading](https://raw.githubusercontent.com/zhiyou720/zhiyou720.github.io/master/img/ASR/ASR-02-07.png)

## Effect of windowing 

### time domain
![loading](https://raw.githubusercontent.com/zhiyou720/zhiyou720.github.io/master/img/ASR/ASR-02-08.png)  

### frequency domain
![loading](https://raw.githubusercontent.com/zhiyou720/zhiyou720.github.io/master/img/ASR/ASR-02-09.png)
![loading](https://raw.githubusercontent.com/zhiyou720/zhiyou720.github.io/master/img/ASR/ASR-02-10.png)  

## Discrete Fourier Transform (DFT)(离散傅立叶变换)
- Purpose: extracts spectral information from a windowed signal (i.e. how much energy at each frequency band)
- Input: windowed signal $$x[0], . . . , x[L−1]$$ (time domain)
- Output: a complex number $$X[k]$$ for each of N frequency bands representing magnitude and phase(相位) for the $$k_th$$ frequency component (frequency domain)
- Discrete Fourier Transform (DFT):  
<center>$$ X[k] =\sum^{N-1}_{n=0} x[n] exp(-j\frac{2\pi}{N} kn)$$</center>  
<p align="right">NB: $$exp(j\theta) = e^{j\theta} = cos(\theta) + j sin(\theta)$$</p>  
- Fast Fourier Transform (FFT)(快速傅立叶变换) — efficient algorithm for computing DFT when $$N$$ is a power of 2, and $$N \geq L$$  

## Wide-band and narrow-band spectrograms(声图谱)
![loading](https://raw.githubusercontent.com/zhiyou720/zhiyou720.github.io/master/img/ASR/ASR-02-11.png)    

## Short-time spectral analysis
![loading](https://raw.githubusercontent.com/zhiyou720/zhiyou720.github.io/master/img/ASR/ASR-02-12.png)    

## DFT Spectrum
![loading](https://raw.githubusercontent.com/zhiyou720/zhiyou720.github.io/master/img/ASR/ASR-02-13.png)    
25ms Hamming window of vowel(元音) /iy/ and its spectrum computed by DFT  

## DFT Spectrum Features for ASR  
- Equally-spaced frequency bands — but human hearing less sensitive at higher frequencies (above ∼ 1000Hz)  
- The estimated power spectrum contains harmonics(谐波) of $$F_0$$, which makes it difficult to estimate the envelope of the spectrum  
![loading](https://raw.githubusercontent.com/zhiyou720/zhiyou720.github.io/master/img/ASR/ASR-02-14.png)
- Frequency bins of STFT are highly correlated each other, i.e. power spectrum representation is highly redundant(冗余)  

## Human hearing  

|Physical quality | Perceptual quality |  
|---------------: |------------------: |  
|        Intensity| Loudness           |  
|Fundamental frequency | Pitch  |
|Spectral shape | Timbre | 
|Onset/offset time | Timing|
|Phase difference in binaural hearing |  Location|  

### Technical terms  

- equal-loudness contours(类似等高线的描绘声音的线)
- masking(掩饰)
- auditory filters (critical-band filters)(听觉过滤)
- critical bandwidth(临界带宽)

#### Equal loudness contour
![loading](https://raw.githubusercontent.com/zhiyou720/zhiyou720.github.io/master/img/ASR/ASR-02-15.png)  

## Nonlinear frequency scaling(非线性频率尺度变换)  

Human hearing is less sensitive to higher frequencies — thus human perception of frequency is nonlinear

- Mel scale:  
$$ M(f) = 1127 ln(1 + \frac{f}{700})$$  
![loading](https://raw.githubusercontent.com/zhiyou720/zhiyou720.github.io/master/img/ASR/ASR-02-16.png)  

- Bark scale:   
$$ b(f ) = 13 arctan(0.00076f ) + 3.5 arctan((\frac{f}{7500})^2)$$  
![loading](https://raw.githubusercontent.com/zhiyou720/zhiyou720.github.io/master/img/ASR/ASR-02-17.png)    

## Mel-Filter Bank(梅尔频谱)

- Apply a mel-scale filter bank to DFT power spectrum to obtain mel-scale power spectrum  
- Each filter collects energy from a number of frequency bands in the DFT  
- Linearly spaced < 1000 Hz, logarithmically spaced > 1000 Hz
p18

$$|Y_t[m]| =\sum^{N}_ {k=1}W_m[k] |X_t[k]|$$  

where: 
  - $$k$$ : DFT bin number ($$1, . . . , N$$)  
  - $$m$$ : mel-filter bank number ($$1, . . . , M$$)  
- How many number of mel-filter channels?
- $$\approx$$ 20 for GMM-HMM based ASR  
- 20 ∼ 40 for DNN (+HMM) based ASR  

### Log Mel Power Spectrum

- Compute the log magnitude squared of each mel-filter bankoutput:  $$log\left| Y[m] \right| ^2$$
  - Taking the log compresses the dynamic range
  - Human sensitivity to signal energy is logarithmic — i.e. humans are less sensitive to small changes in energy at high energy than small changes at low energy
  - Log makes features less variable to acoustic coupling variations(声学耦合差异)
  - Removes phase(相位) information — not important for speech recognition (not everyone agrees with this)  
- Aka “log mel-filter bank outputs” or “FBANK features”, which are widely used in recent DNN-HMM based ASR systems

## Cepstral Analysis(对数倒谱分析)

- Source-Filter model of speech production  
  - Source: Vocal cord vibrations(声带震动) create a glottal(声门的) source waveform  
  - Filter: Source waveform is passed through the vocal tract(声道): position of tongue, jaw(下巴), etc. give it a particular shape and hence a particular filtering characteristic  
- Source characteristics ($$F_0$$, dynamics of glottal pulse(动态的声门的脉冲)) do not help to discriminate between phones  
- The filter specifies the position of the articulators(判定发声器官的位置)  
- ... and hence is directly related to phone discrimination(音素辨别)  
- Cepstral analysis enables us to separate source and filter  

p19

### The Cepstrum(倒频谱)

- Cepstrum obtained by applying inverse DFT to log magnitude spectrum (may be mel-scaled)
- Cepstrum is time-domain (we talk about quefrency)
- Inverse DFT:

<center>$$x[n] = \frac{1}{N}\sum^{N-1}_ {k=0} X[k] exp(j\frac{2\pi}{N}nk)$$</center>   

- Since log power spectrum is real and symmetric(对称的) the inverse DFT is equivalent to a discrete(离散的) cosine transform (DCT):  

<center>$$y_t[n] =\sum^{M-1}_{m=0}log(|Y_t[m]|) cos (n(m+0.5) \frac{\pi}{M})\quad , n = 0, . . . , J$$</center>






















